{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('/content/police-records-project'):\n",
    "    !git clone https://github.com/c-goenka/police-records-project.git\n",
    "    %cd /content/police-records-project\n",
    "    !pip install -r requirements.txt\n",
    "else:\n",
    "    %cd /content/police-records-project\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/content/drive/MyDrive/police-records-project-data/processed\"\n",
    "\n",
    "train_df = pd.read_csv(f\"{data_dir}/train.csv\")\n",
    "test_df = pd.read_csv(f\"{data_dir}/test.csv\")\n",
    "\n",
    "print(f\"Train: {len(train_df)} documents\")\n",
    "print(f\"Test: {len(test_df)} documents\\n\")\n",
    "print(f\"Classes: {train_df['label'].nunique()}\")\n",
    "print(f\"Labels: {sorted(train_df['label'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Model dimensions: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_embeddings",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = model.encode(\n",
    "    train_df['text_clean'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "X_test = model.encode(\n",
    "    test_df['text_clean'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "y_train = train_df['label'].values\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "print(f\"Train embeddings shape: {X_train.shape}\")\n",
    "print(f\"Test embeddings shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        kernel='rbf',\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_classifiers",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy = (y_test == y_pred).mean()\n",
    "\n",
    "    results[name] = {\n",
    "        'model': clf,\n",
    "        'predictions': y_pred,\n",
    "        'macro_f1': macro_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    print(f\"  Macro F1: {macro_f1:.4f}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f} ({(y_test == y_pred).sum()}/{len(y_test)})\\n\")\n",
    "    print(f\"  Correct predictions: {(y_test == y_pred).sum()}/{len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "  'text': test_df['text_clean'],\n",
    "  'true_label': y_test,\n",
    "  'pred_label': best_pred,\n",
    "  'correct': y_test == best_pred\n",
    "})\n",
    "\n",
    "output_path = f\"{data_dir}/embeddings_classifier_results.csv\"\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved results to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, results['Random Forest']['predictions'])\n",
    "labels = sorted(train_df['label'].unique())\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "\n",
    "plt.title(f'Confusion Matrix - Random Forest', fontsize=14, pad=20)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
