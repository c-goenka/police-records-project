{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('/content/police-records-project'):\n",
    "    !git clone https://github.com/c-goenka/police-records-project.git\n",
    "    %cd /content/police-records-project\n",
    "    !pip install -r requirements.txt\n",
    "else:\n",
    "    %cd /content/police-records-project\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/content/drive/MyDrive/police-records-project-data/processed\"\n",
    "\n",
    "train_df = pd.read_csv(f\"{data_dir}/train.csv\")\n",
    "test_df = pd.read_csv(f\"{data_dir}/test.csv\")\n",
    "\n",
    "print(f\"Train: {len(train_df)} documents\")\n",
    "print(f\"Test: {len(test_df)} documents\\n\")\n",
    "print(f\"Classes: {train_df['label'].nunique()}\")\n",
    "print(f\"Labels: {sorted(train_df['label'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Model dimensions: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_embeddings",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = model.encode(\n",
    "    train_df['text_clean'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "X_test = model.encode(\n",
    "    test_df['text_clean'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "y_train = train_df['label'].values\n",
    "y_test = test_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        kernel='rbf',\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_classifiers",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    results[name] = {\n",
    "        'model': clf,\n",
    "        'predictions': y_pred,\n",
    "        'macro_f1': macro_f1,\n",
    "        'micro_f1': micro_f1,\n",
    "        'weighted_f1': weighted_f1\n",
    "    }\n",
    "\n",
    "    print(f\"  Macro F1: {macro_f1:.4f}\")\n",
    "    print(f\"  Micro F1: {micro_f1:.4f}\")\n",
    "    print(f\"  Weighted F1: {weighted_f1:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
