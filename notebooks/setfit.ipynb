{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('/content/police-records-project'):\n",
    "    !git clone https://github.com/c-goenka/police-records-project.git\n",
    "    %cd /content/police-records-project\n",
    "    !pip install -r requirements.txt\n",
    "else:\n",
    "    %cd /content/police-records-project\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/content/drive/MyDrive/police-records-project-data/processed\"\n",
    "\n",
    "train_df = pd.read_csv(f\"{data_dir}/train.csv\")\n",
    "test_df = pd.read_csv(f\"{data_dir}/test.csv\")\n",
    "\n",
    "print(f\"Train: {len(train_df)} documents\")\n",
    "print(f\"Test: {len(test_df)} documents\\n\")\n",
    "print(f\"Classes: {train_df['label'].nunique()}\")\n",
    "print(f\"Labels: {sorted(train_df['label'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {label: idx for idx, label in enumerate(sorted(train_df['label'].unique()))}\n",
    "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
    "\n",
    "train_df['label_id'] = train_df['label'].map(label_to_id)\n",
    "test_df['label_id'] = test_df['label'].map(label_to_id)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': train_df['text_clean'].tolist(),\n",
    "    'label': train_df['label_id'].tolist()\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'text': test_df['text_clean'].tolist(),\n",
    "    'label': test_df['label_id'].tolist()\n",
    "})\n",
    "\n",
    "print(f\"Label mapping:\")\n",
    "for label, idx in sorted(label_to_id.items(), key=lambda x: x[1]):\n",
    "    print(f\"  {idx}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fvx96c1msnu",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model = SetFitModel.from_pretrained(\n",
    "    model_name,\n",
    "    labels=list(label_to_id.keys())\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "al5io45qw6m",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    batch_size=16,\n",
    "    num_epochs=1,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"SetFit Model Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cecsdo9omy",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_df['text_clean'].tolist())\n",
    "y_true = test_df['label_id'].values\n",
    "y_pred = [label_to_id[label] for label in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858936ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'text': test_df['text_clean'],\n",
    "    'true_label': test_df['label'],\n",
    "    'pred_label': [id_to_label[i] for i in y_pred],\n",
    "    'correct': y_true == y_pred\n",
    "})\n",
    "\n",
    "output_path = \"/content/drive/MyDrive/police-records-project-data/processed/setfit_results.csv\"\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved results to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = (y_true == y_pred).mean()\n",
    "\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f} ({(y_true == y_pred).sum()}/{len(y_true)})\")\n",
    "print(f\"Correct predictions: {(y_true == y_pred).sum()}/{len(y_true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "labels = [id_to_label[i] for i in sorted(id_to_label.keys())]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.title('Confusion Matrix - SetFit', fontsize=14, pad=20)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
